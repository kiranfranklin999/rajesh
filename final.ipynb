{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import random,os,io\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, LearningRateScheduler, ModelCheckpoint,CSVLogger\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42039, 16), (42039, 1), (10935, 16), (10935, 1), (10934, 16), (10934, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dep_train=pd.read_csv(\"D:\\\\bro\\\\Analysis\\\\mSANN\\\\cd\\\\XTr.dat\",sep='\\s+',names=[str(i) for i in range(0,16)])\n",
    "indep_train=pd.read_csv(\"D:\\\\bro\\\\Analysis\\\\mSANN\\\\cd\\\\yTr.dat\",sep='\\s+',names=['target'])\n",
    "dep_val=pd.read_csv(\"D:\\\\bro\\\\Analysis\\\\mSANN\\\\cd\\\\XV.dat\",sep='\\s+',names=[str(i) for i in range(0,16)])\n",
    "indep_val=pd.read_csv(\"D:\\\\bro\\\\Analysis\\\\mSANN\\\\cd\\\\yV.dat\",sep='\\s+',names=[\"target\"])\n",
    "dep_test=pd.read_csv(\"D:\\\\bro\\\\Analysis\\\\mSANN\\\\cd\\\\XT.dat\",sep='\\s+',names=[str(i) for i in range(0,16)])\n",
    "indep_test=pd.read_csv(\"D:\\\\bro\\\\Analysis\\\\mSANN\\\\cd\\\\yT.dat\",sep='\\s+',names=[\"target\"])\n",
    "\n",
    "dep_train.shape,indep_train.shape,dep_val.shape,indep_val.shape,dep_test.shape,indep_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SobolevNetwork(Model):\n",
    "    def __init__(self, input_dim, num_hidden,init = None):\n",
    "        super(SobolevNetwork, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.num_hidden = num_hidden\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.input_dim, self.num_hidden],stddev=0.1))\n",
    "        self.b1 = tf.Variable(tf.ones([self.num_hidden]))\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.num_hidden, self.num_hidden],stddev=0.1))\n",
    "        self.b2 = tf.Variable(tf.ones([self.num_hidden]))\n",
    "        self.W3 = tf.Variable(tf.random.normal([self.num_hidden, self.num_hidden],stddev=0.1))\n",
    "        self.b3 = tf.Variable(tf.ones([self.num_hidden]))\n",
    "        self.W4 = tf.Variable(tf.random.normal([self.num_hidden, self.num_hidden],stddev=0.1))\n",
    "        self.b4 = tf.Variable(tf.ones([self.num_hidden]))\n",
    "        self.W5 = tf.Variable(tf.random.normal([self.num_hidden, self.num_hidden],stddev=0.1))\n",
    "        self.b5 = tf.Variable(tf.ones([self.num_hidden]))\n",
    "        self.W6 = tf.Variable(tf.random.normal([self.num_hidden, self.num_hidden],stddev=0.1))\n",
    "        self.b6 = tf.Variable(tf.ones([self.num_hidden]))        \n",
    "        self.W7 = tf.Variable(tf.random.normal([self.num_hidden, 1],stddev=0.1))\n",
    "        self.b7 = tf.Variable(tf.ones([1]))\n",
    "        self.w = [(self.W1, self.b1), (self.W2, self.b2), (self.W3, self.b3),(self.W4, self.b4), (self.W5, self.b5), (self.W6, self.b6),(self.W7, self.b7)]\n",
    "        \n",
    "    def call(self, X):\n",
    "        #Input layer\n",
    "        out = X\n",
    "        #Hidden layers\n",
    "        W,b = self.w[0]\n",
    "        out = tf.nn.tanh(tf.matmul(out, W) + b)\n",
    "        W,b = self.w[1]\n",
    "        out = tf.nn.tanh(tf.matmul(out, W) + b)\n",
    "        W,b = self.w[2]\n",
    "        out = tf.nn.sigmoid(tf.matmul(out, W) + b)\n",
    "        W,b = self.w[3]\n",
    "        out = tf.nn.sigmoid(tf.matmul(out, W) + b)\n",
    "        W,b = self.w[4]\n",
    "        out = tf.nn.leaky_relu(tf.matmul(out, W) + b)\n",
    "        W,b = self.w[5]\n",
    "        out = tf.nn.relu(tf.matmul(out, W) + b)\n",
    "        #Output layer\n",
    "        W,b = self.w[-1]\n",
    "        out = tf.matmul(out, W) + b\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\n For Epoch Number {} the model has loss[mean_absolute_error] of {}\".format(epoch+1, logs[\"loss\"]))\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        print(\"\\n For Batch Number {} the model has loss[mean_absolute_error] of {}\".format(batch+1, logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_callback = CSVLogger( 'logs.csv',separator=',',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping( monitor='val_loss',min_delta=0,patience=2, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedular(epoch, lr):\n",
    "    if epoch <= 3:\n",
    "        learning_rate = lr\n",
    "    else:\n",
    "        learning_rate = lr * tf.math.exp(-0.1)\n",
    "        learning_rate = learning_rate.numpy()\n",
    "    \n",
    "\n",
    "    # with train_writer.as_default():\n",
    "    #     tf.summary.scalar('LearningRateScheduler', data= learning_rate, step= epoch)\n",
    "    \n",
    "    return learning_rate\n",
    "\n",
    "schedular_callback = LearningRateScheduler(schedular, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_1 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_snn= SobolevNetwork(input_dim=16,num_hidden=num_hidden_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_snn.compile(optimizer=tf.keras.optimizers.Adam(),  \n",
    "            loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 1.3535337448120117}\n",
      " 1/43 [..............................] - ETA: 2:31 - loss: 1.3535\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 1.3379336595535278}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 1.3223109245300293}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 1.3067392110824585}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 1.291207194328308}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 1.2756702899932861}\n",
      " 6/43 [===>..........................] - ETA: 0s - loss: 1.2757  \n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 1.2601815462112427}\n",
      "\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 1.2447007894515991}\n",
      "\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 1.2292218208312988}\n",
      "\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 1.2137541770935059}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 1.198305368423462}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 1.1828533411026}\n",
      "12/43 [=======>......................] - ETA: 0s - loss: 1.1829\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 1.1674013137817383}\n",
      "\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 1.1519443988800049}\n",
      "\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 1.1364977359771729}\n",
      "\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 1.1210540533065796}\n",
      "\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 1.1055864095687866}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 1.0901188850402832}\n",
      "18/43 [===========>..................] - ETA: 0s - loss: 1.0901\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 1.0746262073516846}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 1.0591330528259277}\n",
      "\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 1.043618083000183}\n",
      "\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 1.0280641317367554}\n",
      "\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 1.0124810934066772}\n",
      "\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.9968757033348083}\n",
      "24/43 [===============>..............] - ETA: 0s - loss: 0.9969\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.981234610080719}\n",
      "\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.9655656814575195}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.9498504996299744}\n",
      "\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.9340922236442566}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.91828852891922}\n",
      "\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.9024418592453003}\n",
      "30/43 [===================>..........] - ETA: 0s - loss: 0.9024\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.8865341544151306}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.870571494102478}\n",
      "\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.8545463681221008}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.8384550213813782}\n",
      "\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.8222965598106384}\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.8223\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.8060531616210938}\n",
      "\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.7897367477416992}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.7733361124992371}\n",
      "\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.7568477392196655}\n",
      "\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.74025958776474}\n",
      "\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.723572313785553}\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.7236\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.7067848443984985}\n",
      "\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.7061470150947571}\n",
      "\n",
      " For Epoch Number 1 the model has loss[mean_absolute_error] of 0.7061470150947571\n",
      "43/43 [==============================] - 5s 38ms/step - loss: 0.7061 - val_loss: 0.0473 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 0.04716727137565613}\n",
      " 1/43 [..............................] - ETA: 0s - loss: 0.0472\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 0.0574299618601799}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 0.06551240384578705}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 0.0718425065279007}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 0.076439768075943}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 0.07951053977012634}\n",
      "\n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 0.08112190663814545}\n",
      "\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 0.08141808956861496}\n",
      " 8/43 [====>.........................] - ETA: 0s - loss: 0.0814\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 0.08055681735277176}\n",
      "\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 0.07861051708459854}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 0.07570122927427292}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 0.07187547534704208}\n",
      "\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 0.06725414842367172}\n",
      "\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 0.06302530318498611}\n",
      "14/43 [========>.....................] - ETA: 0s - loss: 0.0630\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 0.060288745909929276}\n",
      "\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 0.05848337337374687}\n",
      "\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 0.05720525234937668}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 0.056149743497371674}\n",
      "\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 0.05510306730866432}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 0.053920526057481766}\n",
      "\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 0.052497245371341705}\n",
      "21/43 [=============>................] - ETA: 0s - loss: 0.0525\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 0.050749726593494415}\n",
      "\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 0.04867572337388992}\n",
      "\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.04711546376347542}\n",
      "\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.04601770639419556}\n",
      "\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.04517892748117447}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.044431429356336594}\n",
      "\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.04364544525742531}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.0427142009139061}\n",
      "29/43 [===================>..........] - ETA: 0s - loss: 0.0427\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.041565682739019394}\n",
      "\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.04033852368593216}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.039389386773109436}\n",
      "\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.03859938681125641}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.03785838186740875}\n",
      "\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.037074632942676544}\n",
      "\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.03618312254548073}\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 0.0362\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.035307321697473526}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.03457864373922348}\n",
      "\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.033902425318956375}\n",
      "\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.03318734094500542}\n",
      "\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.03243318572640419}\n",
      "\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.031782135367393494}\n",
      "\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.031758036464452744}\n",
      "43/43 [==============================] - ETA: 0s - loss: 0.0318\n",
      " For Epoch Number 2 the model has loss[mean_absolute_error] of 0.031758036464452744\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0318 - val_loss: 0.0042 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 3/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 0.00414885813370347}\n",
      " 1/43 [..............................] - ETA: 0s - loss: 0.0041\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 0.003196154022589326}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 0.003685073461383581}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 0.003925482276827097}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 0.0035756370052695274}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 0.0036108812782913446}\n",
      "\n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 0.003725262824445963}\n",
      "\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 0.003662064438685775}\n",
      " 8/43 [====>.........................] - ETA: 0s - loss: 0.0037\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 0.003493616823107004}\n",
      "\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 0.0035236754920333624}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 0.003469536080956459}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 0.0033799251541495323}\n",
      "\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 0.0033914700616151094}\n",
      "\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 0.0033591128885746002}\n",
      "\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 0.003281232202425599}\n",
      "15/43 [=========>....................] - ETA: 0s - loss: 0.0033\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 0.0032898446079343557}\n",
      "\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 0.003221424762159586}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 0.0031822919845581055}\n",
      "\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 0.0031686972361057997}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 0.0031185054685920477}\n",
      "\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 0.0030877983663231134}\n",
      "\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 0.003066592151299119}\n",
      "\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 0.003020115429535508}\n",
      "23/43 [===============>..............] - ETA: 0s - loss: 0.0030\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.0030006172601133585}\n",
      "\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.0029668034985661507}\n",
      "\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.0029350260738283396}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.0029174957890063524}\n",
      "\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.002889389405027032}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.002870413940399885}\n",
      "\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.0028496012091636658}\n",
      "30/43 [===================>..........] - ETA: 0s - loss: 0.0028\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.00282412301748991}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.0028063219506293535}\n",
      "\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.0027894466184079647}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.0027749512810260057}\n",
      "\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.0027605630457401276}\n",
      "\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.0027399857062846422}\n",
      "36/43 [========================>.....] - ETA: 0s - loss: 0.0027\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.0027279930654913187}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.002712657442316413}\n",
      "\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.0026995178777724504}\n",
      "\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.002687622793018818}\n",
      "\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.002674192888662219}\n",
      "\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.002664322266355157}\n",
      "42/43 [============================>.] - ETA: 0s - loss: 0.0027\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.002663683844730258}\n",
      "\n",
      " For Epoch Number 3 the model has loss[mean_absolute_error] of 0.002663683844730258\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 0.0021 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 4/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 0.002038465114310384}\n",
      " 1/43 [..............................] - ETA: 0s - loss: 0.0020\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 0.0020265986677259207}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 0.0021082712337374687}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 0.0021201102063059807}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 0.0021016139071434736}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 0.0020993133075535297}\n",
      "\n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 0.002094296272844076}\n",
      "\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 0.0021059117279946804}\n",
      "\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 0.0021095683332532644}\n",
      " 9/43 [=====>........................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 0.002118412172421813}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 0.0021065690089017153}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 0.0021229912526905537}\n",
      "\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 0.002135370159521699}\n",
      "\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 0.0021349561866372824}\n",
      "\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 0.0021251437719911337}\n",
      "\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 0.002113893860951066}\n",
      "16/43 [==========>...................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 0.002106731291860342}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 0.0021124829072505236}\n",
      "\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 0.0021176980808377266}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 0.002116649877279997}\n",
      "\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 0.0021060060244053602}\n",
      "\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 0.002103991573676467}\n",
      "22/43 [==============>...............] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 0.0021058626007288694}\n",
      "\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.00210455316118896}\n",
      "\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.0021029533818364143}\n",
      "\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.002102359663695097}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.002106558531522751}\n",
      "\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.002102941507473588}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.0021025643218308687}\n",
      "29/43 [===================>..........] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.0020981584675610065}\n",
      "\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.0021012842189520597}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.002100257435813546}\n",
      "\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.0020994325168430805}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.002100563608109951}\n",
      "\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.002100073266774416}\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.00209805928170681}\n",
      "\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.0020969018805772066}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.002097743097692728}\n",
      "\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.0021007535979151726}\n",
      "\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.0021005230955779552}\n",
      "40/43 [==========================>...] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.0020995561499148607}\n",
      "\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.002097605960443616}\n",
      "\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.002097645541653037}\n",
      "\n",
      " For Epoch Number 4 the model has loss[mean_absolute_error] of 0.002097645541653037\n",
      "43/43 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009048374486155808.\n",
      "Epoch 5/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 0.0022070524282753468}\n",
      " 1/43 [..............................] - ETA: 0s - loss: 0.0022\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 0.002185336546972394}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 0.0021785362623631954}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 0.002152437809854746}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 0.002118168631568551}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 0.002110686618834734}\n",
      "\n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 0.0021214219741523266}\n",
      "\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 0.00210733525454998}\n",
      " 8/43 [====>.........................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 0.0020969260949641466}\n",
      "\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 0.002090384950861335}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 0.0020937358494848013}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 0.002099184785038233}\n",
      "\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 0.002098000841215253}\n",
      "\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 0.0021046618930995464}\n",
      "\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 0.0020947724115103483}\n",
      "15/43 [=========>....................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 0.002087203785777092}\n",
      "\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 0.002088176319375634}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 0.002088547684252262}\n",
      "\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 0.002083645900711417}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 0.0020837364718317986}\n",
      "\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 0.002078297547996044}\n",
      "\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 0.0020808689296245575}\n",
      "\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 0.0020876664202660322}\n",
      "23/43 [===============>..............] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.002095106290653348}\n",
      "\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.0020949814934283495}\n",
      "\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.0020953286439180374}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.002091769129037857}\n",
      "\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.002093637129291892}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.002094550523906946}\n",
      "29/43 [===================>..........] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.002093678805977106}\n",
      "\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.0020926198922097683}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.0020886545535176992}\n",
      "\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.0020855965558439493}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.002087480155751109}\n",
      "\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.0020910475868731737}\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.0020945474971085787}\n",
      "\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.002093798713758588}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.0020900669042021036}\n",
      "\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.0020904375705868006}\n",
      "\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.0020916610956192017}\n",
      "\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.0020911316387355328}\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.00209329673089087}\n",
      "\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.0020939207170158625}\n",
      "\n",
      " For Epoch Number 5 the model has loss[mean_absolute_error] of 0.0020939207170158625\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 9.0484e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0008187307976186275.\n",
      "Epoch 6/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 0.0020770349074155092}\n",
      " 1/43 [..............................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 0.00209153164178133}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 0.0020595977548509836}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 0.002101354533806443}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 0.002097924705594778}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 0.002136027906090021}\n",
      "\n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 0.0021230257116258144}\n",
      " 7/43 [===>..........................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 0.00212598848156631}\n",
      "\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 0.002118919277563691}\n",
      "\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 0.002116888528689742}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 0.0021070672664791346}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 0.0021087254863232374}\n",
      "\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 0.0021018744446337223}\n",
      "13/43 [========>.....................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 0.0021075825206935406}\n",
      "\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 0.0021110151428729296}\n",
      "\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 0.002106231404468417}\n",
      "\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 0.0020907132420688868}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 0.0020886424463242292}\n",
      "\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 0.0020795753225684166}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 0.0020806665997952223}\n",
      "20/43 [============>.................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 0.002086976310238242}\n",
      "\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 0.002089387970045209}\n",
      "\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 0.002094912575557828}\n",
      "\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.0020976411178708076}\n",
      "\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.002104694489389658}\n",
      "25/43 [================>.............] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.002102463273331523}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.0021085122134536505}\n",
      "\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.0021060905419290066}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.002102506812661886}\n",
      "\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.002100704237818718}\n",
      "\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.002105614636093378}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.0021111657842993736}\n",
      "32/43 [=====================>........] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.0021064532920718193}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.0021060232538729906}\n",
      "\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.002106432570144534}\n",
      "\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.002103387610986829}\n",
      "\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.002099493285641074}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.0021002069115638733}\n",
      "38/43 [=========================>....] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.0021017324179410934}\n",
      "\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.0021008215844631195}\n",
      "\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.0020988616161048412}\n",
      "\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.0020999673288315535}\n",
      "\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.002099703997373581}\n",
      "\n",
      " For Epoch Number 6 the model has loss[mean_absolute_error] of 0.002099703997373581\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 8.1873e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0007408182718791068.\n",
      "Epoch 7/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 0.0022867138031870127}\n",
      " 1/43 [..............................] - ETA: 0s - loss: 0.0023\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 0.002209128811955452}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 0.0021626364905387163}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 0.0021221251226961613}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 0.0021340884268283844}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 0.0021522969473153353}\n",
      "\n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 0.0021681347861886024}\n",
      "\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 0.0021374840289354324}\n",
      " 8/43 [====>.........................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 0.0021258676424622536}\n",
      "\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 0.0021124810446053743}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 0.0021064707543700933}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 0.0021196408197283745}\n",
      "\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 0.0021256429608911276}\n",
      "\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 0.002122083678841591}\n",
      "14/43 [========>.....................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 0.002130800625309348}\n",
      "\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 0.00212881900370121}\n",
      "\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 0.002121239434927702}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 0.0021230289712548256}\n",
      "\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 0.002118876203894615}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 0.0021229798439890146}\n",
      "\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 0.0021157190203666687}\n",
      "\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 0.002112375106662512}\n",
      "22/43 [==============>...............] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 0.002104462357237935}\n",
      "\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.002100942889228463}\n",
      "\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.002101280028000474}\n",
      "\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.00210176152177155}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.0020982474088668823}\n",
      "\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.0020929358433932066}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.002092347014695406}\n",
      "29/43 [===================>..........] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.0020896345376968384}\n",
      "\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.0020903279073536396}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.0020887197460979223}\n",
      "\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.002091251313686371}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.0020904592238366604}\n",
      "\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.002085173036903143}\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.0020870761945843697}\n",
      "\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.0020849285647273064}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.002084936946630478}\n",
      "\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.002084626816213131}\n",
      "\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.0020834507886320353}\n",
      "\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.002084735780954361}\n",
      "41/43 [===========================>..] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.0020850584842264652}\n",
      "\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.0020845814142376184}\n",
      "\n",
      " For Epoch Number 7 the model has loss[mean_absolute_error] of 0.0020845814142376184\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.0021 - val_loss: 0.0021 - lr: 7.4082e-04\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0006703201215714216.\n",
      "Epoch 8/8\n",
      "\n",
      " For Batch Number 1 the model has loss[mean_absolute_error] of {'loss': 0.0019369757501408458}\n",
      " 1/43 [..............................] - ETA: 0s - loss: 0.0019\n",
      " For Batch Number 2 the model has loss[mean_absolute_error] of {'loss': 0.0020435519982129335}\n",
      "\n",
      " For Batch Number 3 the model has loss[mean_absolute_error] of {'loss': 0.0021087622735649347}\n",
      "\n",
      " For Batch Number 4 the model has loss[mean_absolute_error] of {'loss': 0.002115138340741396}\n",
      "\n",
      " For Batch Number 5 the model has loss[mean_absolute_error] of {'loss': 0.0021228077821433544}\n",
      "\n",
      " For Batch Number 6 the model has loss[mean_absolute_error] of {'loss': 0.0020939887035638094}\n",
      "\n",
      " For Batch Number 7 the model has loss[mean_absolute_error] of {'loss': 0.0021052889060229063}\n",
      "\n",
      " For Batch Number 8 the model has loss[mean_absolute_error] of {'loss': 0.0020742397755384445}\n",
      " 8/43 [====>.........................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 9 the model has loss[mean_absolute_error] of {'loss': 0.0020622904412448406}\n",
      "\n",
      " For Batch Number 10 the model has loss[mean_absolute_error] of {'loss': 0.0020473208278417587}\n",
      "\n",
      " For Batch Number 11 the model has loss[mean_absolute_error] of {'loss': 0.002051284536719322}\n",
      "\n",
      " For Batch Number 12 the model has loss[mean_absolute_error] of {'loss': 0.0020425973925739527}\n",
      "\n",
      " For Batch Number 13 the model has loss[mean_absolute_error] of {'loss': 0.0020493369083851576}\n",
      "\n",
      " For Batch Number 14 the model has loss[mean_absolute_error] of {'loss': 0.00205351784825325}\n",
      "14/43 [========>.....................] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 15 the model has loss[mean_absolute_error] of {'loss': 0.002058137208223343}\n",
      "\n",
      " For Batch Number 16 the model has loss[mean_absolute_error] of {'loss': 0.0020530838519334793}\n",
      "\n",
      " For Batch Number 17 the model has loss[mean_absolute_error] of {'loss': 0.002055628690868616}\n",
      "\n",
      " For Batch Number 18 the model has loss[mean_absolute_error] of {'loss': 0.0020522226113826036}\n",
      "\n",
      " For Batch Number 19 the model has loss[mean_absolute_error] of {'loss': 0.0020461755339056253}\n",
      "\n",
      " For Batch Number 20 the model has loss[mean_absolute_error] of {'loss': 0.0020450372248888016}\n",
      "20/43 [============>.................] - ETA: 0s - loss: 0.0020\n",
      " For Batch Number 21 the model has loss[mean_absolute_error] of {'loss': 0.0020474903285503387}\n",
      "\n",
      " For Batch Number 22 the model has loss[mean_absolute_error] of {'loss': 0.0020466670393943787}\n",
      "\n",
      " For Batch Number 23 the model has loss[mean_absolute_error] of {'loss': 0.002053175587207079}\n",
      "\n",
      " For Batch Number 24 the model has loss[mean_absolute_error] of {'loss': 0.0020567369647324085}\n",
      "\n",
      " For Batch Number 25 the model has loss[mean_absolute_error] of {'loss': 0.0020525141153484583}\n",
      "\n",
      " For Batch Number 26 the model has loss[mean_absolute_error] of {'loss': 0.0020527299493551254}\n",
      "\n",
      " For Batch Number 27 the model has loss[mean_absolute_error] of {'loss': 0.0020547951571643353}\n",
      "27/43 [=================>............] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 28 the model has loss[mean_absolute_error] of {'loss': 0.0020543825812637806}\n",
      "\n",
      " For Batch Number 29 the model has loss[mean_absolute_error] of {'loss': 0.0020583919249475002}\n",
      "\n",
      " For Batch Number 30 the model has loss[mean_absolute_error] of {'loss': 0.0020569846965372562}\n",
      "\n",
      " For Batch Number 31 the model has loss[mean_absolute_error] of {'loss': 0.0020580037962645292}\n",
      "\n",
      " For Batch Number 32 the model has loss[mean_absolute_error] of {'loss': 0.0020589723717421293}\n",
      "\n",
      " For Batch Number 33 the model has loss[mean_absolute_error] of {'loss': 0.002059374703094363}\n",
      "\n",
      " For Batch Number 34 the model has loss[mean_absolute_error] of {'loss': 0.0020602671429514885}\n",
      "34/43 [======================>.......] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 35 the model has loss[mean_absolute_error] of {'loss': 0.0020658266730606556}\n",
      "\n",
      " For Batch Number 36 the model has loss[mean_absolute_error] of {'loss': 0.002066356362774968}\n",
      "\n",
      " For Batch Number 37 the model has loss[mean_absolute_error] of {'loss': 0.002062652027234435}\n",
      "\n",
      " For Batch Number 38 the model has loss[mean_absolute_error] of {'loss': 0.002063894644379616}\n",
      "\n",
      " For Batch Number 39 the model has loss[mean_absolute_error] of {'loss': 0.0020677403081208467}\n",
      "39/43 [==========================>...] - ETA: 0s - loss: 0.0021\n",
      " For Batch Number 40 the model has loss[mean_absolute_error] of {'loss': 0.0020652152597904205}\n",
      "\n",
      " For Batch Number 41 the model has loss[mean_absolute_error] of {'loss': 0.0020662585739046335}\n",
      "\n",
      " For Batch Number 42 the model has loss[mean_absolute_error] of {'loss': 0.0020634224638342857}\n",
      "\n",
      " For Batch Number 43 the model has loss[mean_absolute_error] of {'loss': 0.002063018037006259}\n",
      "\n",
      " For Epoch Number 8 the model has loss[mean_absolute_error] of 0.002063018037006259\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.0021 - val_loss: 0.0022 - lr: 6.7032e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb94a1daf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_snn.fit(dep_train, indep_train, validation_data=(dep_val,indep_val),batch_size = 1000, epochs = 8, callbacks=[schedular_callback,LossCallback(), csv_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 2s 4ms/step - loss: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002203913638368249"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_snn.evaluate(dep_test, indep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 2s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0103789 ],\n",
       "       [0.01052278],\n",
       "       [0.01038009],\n",
       "       ...,\n",
       "       [0.01052535],\n",
       "       [0.01054573],\n",
       "       [0.01016152]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_snn.predict(dep_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13bec6b3e23dd0921d86a1ec88a5a342f8b423eb92f661fc2c47e8b6a92d2fe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
