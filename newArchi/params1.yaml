activation_1: tanh
activation_2: tanh
activation_3: relu
activation_4: relu
activation_5: relu
activation_6: tanh
activation_7: relu
activation_8: tanh
learning_rate: 0.001
num_layers: 5
units_1: 10
units_2: 2
units_3: 6
units_4: 4
units_5: 10
units_6: 4
units_7: 4
weights: random_normal
