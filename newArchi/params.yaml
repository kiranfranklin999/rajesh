activation_1: relu
activation_2: relu
activation_3: relu
activation_4: tanh
activation_5: tanh
activation_6: tanh
activation_7: tanh
activation_8: relu
learning_rate: 0.0001
num_layers: 6
units_0: 8
units_1: 8
units_2: 6
units_3: 8
units_4: 6
units_5: 8
weights: random_uniform
